{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from deep_ensemble import deep_ensemble_FP as deep_ensemble_MLP\n",
    "from deep_ensemble import deep_ensemble_Graph as deep_ensemble_Graph\n",
    "import math \n",
    "import argparse\n",
    "import sys\n",
    "from tqdm import tqdm \n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "# import get_fsmol_dataloader as fsmol\n",
    "import seaborn as sns\n",
    "from EDKT_data.Data_FP_fsmol import deep_gp_data as deep_gp_data_fp\n",
    "from EDKT_data.Data_Graph_fsmol import deep_gp_data as deep_gp_data_graph\n",
    "import pickle \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_id_train_test_split = np.load('../Data_for_publication/fsmol_multifp/split_dic.pkl', allow_pickle=True)\n",
    "test_assay_ls = assay_id_train_test_split['test_assays']\n",
    "eval_assay_ls = assay_id_train_test_split['valid_assays']\n",
    "\n",
    "few_shot_number = 128\n",
    "\n",
    "# load fp data\n",
    "data_path = '../Data_for_publication/fsmol_multifp/all_data_fp.pkl'\n",
    "data_path_test = f'../Data_for_publication/fsmol_multifp/all_data_fp_test_10fold_{few_shot_number}.pkl'\n",
    "data_path_valid = f'../Data_for_publication/fsmol_multifp/all_data_fp_valid_10fold_{few_shot_number}.pkl'\n",
    "data_test_fp = deep_gp_data_fp(data_path, data_path_test)\n",
    "data_valid_fp = deep_gp_data_fp(data_path, data_path_valid)\n",
    "# load graph data\n",
    "data_path = '../Data_for_publication/fsmol_multifp/all_data_graph.pkl'\n",
    "data_path_test = f'../Data_for_publication/fsmol_multifp/all_data_graph_test_10fold_{few_shot_number}.pkl'\n",
    "data_path_valid = f'../Data_for_publication/fsmol_multifp/all_data_graph_valid_10fold_{few_shot_number}.pkl'\n",
    "data_test_graph = deep_gp_data_graph(data_path, data_path_test)\n",
    "data_valid_graph = deep_gp_data_graph(data_path, data_path_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args_list=None):\n",
    "    parser = argparse.ArgumentParser(description=\"DeepGP Training Script\")\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=42, help=\"random_seed\")\n",
    "    parser.add_argument(\"--dataset\", type=str, help=\"what dataset to use\", default='fsmol')\n",
    "    parser.add_argument(\"--encode_method\", type=str, help=\"what encoder to use\", default='FP')\n",
    "    parser.add_argument(\"--num_encoder\", type=int, default=2, help=\"num_encoder\")\n",
    "    parser.add_argument(\"--allow_NCL\", action=\"store_true\", help=\"whether use NCL\")\n",
    "    \n",
    "    # First parse to get dataset and encode_method\n",
    "    temp_args, _ = parser.parse_known_args(args_list)\n",
    "    \n",
    "    if temp_args.dataset == 'fsmol':\n",
    "        parser.add_argument(\"--FP_input_dim\", type=int, default=2024, help=\"FP input dimension\")\n",
    "        parser.add_argument(\"--Graph_input_dim\", type=int, default=32, help=\"Graph input dimension\")\n",
    "    elif temp_args.dataset == 'pQSAR':\n",
    "        parser.add_argument(\"--FP_input_dim\", type=int, default=1024, help=\"FP input dimension\")\n",
    "        parser.add_argument(\"--Graph_input_dim\", type=int, default=30, help=\"Graph input dimension\")\n",
    "        parser.add_argument(\"--group_id\", type=int, default=0, help=\"group_id\")\n",
    "    \n",
    "    parser.add_argument(\"--world_size\", type=int, default=6, help=\"number of GPUs to use\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=10, help=\"batch size\")\n",
    "    if 'FP' in temp_args.encode_method:\n",
    "        parser.add_argument(\"--lr\", type=float, help=\"learning rate\", default=0.001)\n",
    "    elif 'Graph' in temp_args.encode_method:\n",
    "        parser.add_argument(\"--lr\", type=float, help=\"learning rate\", default=0.0005)\n",
    "    \n",
    "    args = parser.parse_args(args_list)\n",
    "    \n",
    "    # Import required modules based on arguments\n",
    "    if 'FP' in args.encode_method:\n",
    "        from deep_ensemble import deep_ensemble_FP as deep_ensemble\n",
    "        if args.dataset == 'fsmol':\n",
    "            from EDKT_data.Data_FP_fsmol import deep_gp_data\n",
    "            from DKT_dataset import MLP_train_dataset_fsmol as train_dataset \n",
    "            from DKT_dataset import MLP_eval_dataset_fsmol as eval_dataset\n",
    "        elif args.dataset == 'pQSAR':\n",
    "            from EDKT_data.Data_FP_pQSAR import deep_gp_data\n",
    "            from DKT_dataset import MLP_train_dataset_pQSAR as train_dataset\n",
    "            from DKT_dataset import MLP_eval_dataset_pQSAR as eval_dataset\n",
    "    elif 'Graph' in args.encode_method:\n",
    "        from deep_ensemble import deep_ensemble_Graph as deep_ensemble\n",
    "        if args.dataset == 'fsmol':\n",
    "            from EDKT_data.Data_Graph_fsmol import deep_gp_data\n",
    "            from DKT_dataset import Graph_train_dataset_fsmol as train_dataset\n",
    "            from DKT_dataset import Graph_eval_dataset_fsmol as eval_dataset\n",
    "        elif args.dataset == 'pQSAR':\n",
    "            from EDKT_data.Data_Graph_pQSAR import deep_gp_data\n",
    "            from DKT_dataset import Graph_train_dataset_pQSAR as train_dataset\n",
    "            from DKT_dataset import Graph_eval_dataset_pQSAR as eval_dataset\n",
    "    \n",
    "    # Add imported modules to args\n",
    "    args.deep_ensemble = deep_ensemble\n",
    "    args.deep_gp_data = deep_gp_data\n",
    "    args.train_dataset = train_dataset\n",
    "    args.eval_dataset = eval_dataset\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load FP model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(deep_ensemble_MLP)\n",
    "def load_fp_model(model_args):\n",
    "    try:\n",
    "        fp_model = deep_ensemble_MLP.ensemble_deep_gp(model_args)\n",
    "        # Load state dict\n",
    "        model_path = f'../Model_for_publication/Dataset:{model_args.dataset}_Method:{model_args.encode_method}_Num:{model_args.num_encoder}_NCL:{model_args.allow_NCL}_seed:{model_args.random_seed}.pth'\n",
    "        state_dict = torch.load(model_path)\n",
    "        # Process state dict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] if k.startswith('module.') else k\n",
    "            new_state_dict[name] = v\n",
    "        # Load and verify\n",
    "        fp_model.load_state_dict(new_state_dict)\n",
    "        fp_model.eval()\n",
    "        print(f\"✓ FP Model loaded successfully from {model_path}\")\n",
    "        return fp_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load FP model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load graph model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(deep_ensemble_Graph)\n",
    "def load_graph_model(model_args):\n",
    "    try:\n",
    "        graph_model = deep_ensemble_Graph.ensemble_deep_gp(model_args)\n",
    "        \n",
    "        # Load state dict\n",
    "        model_path = f'../Model_for_publication/Dataset:{model_args.dataset}_Method:{model_args.encode_method}_Num:{model_args.num_encoder}_NCL:{model_args.allow_NCL}_seed:{model_args.random_seed}.pth'\n",
    "        state_dict = torch.load(model_path)\n",
    "        \n",
    "        # Process state dict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] if k.startswith('module.') else k\n",
    "            new_state_dict[name] = v\n",
    "            \n",
    "        # Load and verify\n",
    "        graph_model.load_state_dict(new_state_dict)\n",
    "        graph_model.eval()\n",
    "        \n",
    "        # print(f\"✓ Model loaded successfully from {model_path}\")\n",
    "        return graph_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(f\"✗ Failed to load model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance_overall_fp(assay_ls, model, folde_id, mode = 'test'):\n",
    "    r2_ls = []\n",
    "    for assay_id in assay_ls:\n",
    "        if mode == 'test':\n",
    "            task_data = data_test_fp.tensorize_test(assay_id, folde_id)\n",
    "        elif mode == 'valid':\n",
    "             task_data = data_valid_fp.tensorize_test(assay_id, folde_id)\n",
    "        prediction = model.prediction(task_data, 'cpu')\n",
    "        y_label = task_data[3]\n",
    "        r2 = np.corrcoef(torch.tensor(y_label).reshape(-1), prediction.detach().cpu().numpy().reshape(-1))[0,1]**2\n",
    "        r2_ls.append(r2)\n",
    "    return r2_ls\n",
    "\n",
    "def get_model_performance_overall_graph(assay_ls, model, folde_id, mode = 'test'):\n",
    "    r2_ls = []\n",
    "    for assay_id in assay_ls:\n",
    "        if mode == 'test':\n",
    "            task_data = data_test_graph.smiles_to_graph_test(assay_id, folde_id)\n",
    "        elif mode == 'valid':\n",
    "             task_data = data_valid_graph.smiles_to_graph_test(assay_id, folde_id)\n",
    "        prediction = model.prediction(task_data, 'cpu')\n",
    "        y_label = task_data[3]\n",
    "        r2 = np.corrcoef(torch.tensor(y_label).reshape(-1), prediction.detach().cpu().numpy().reshape(-1))[0,1]**2\n",
    "        r2_ls.append(r2)\n",
    "    return r2_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to load FP model: [Errno 2] No such file or directory: '../Model_for_publication/Dataset:fsmol_Method:FPRGB_Num:50_NCL:False_seed:42.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3250626/294271057.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "model_args = [\n",
    "    \"--num_encoder\", \"50\",\n",
    "    \"--dataset\", \"fsmol\",\n",
    "    \"--encode_method\", \"FPRGB\",\n",
    "]\n",
    "args_fp = parse_args(model_args)\n",
    "fp_model = load_fp_model(args_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_dict_per_model(assay_ls, device, fold_id, mode = 'valid'):\n",
    "    # graph model prediction, first load then predict\n",
    "    # for model_architecture in ['GraphGAT', 'GraphGIN', 'GraphSAGE']:\n",
    "    # for model_architecture in ['GraphGCN', 'GraphGAT', 'GraphGIN', 'GraphSAGE']:\n",
    "    #     prediction_dic = {}\n",
    "    #     for random_seed in range(11):\n",
    "    #         model_args = [\n",
    "    #             \"--num_encoder\", \"2\",\n",
    "    #             \"--dataset\", \"fsmol\",\n",
    "    #             \"--encode_method\", model_architecture,\n",
    "    #             \"--random_seed\", str(random_seed),\n",
    "    #         ]\n",
    "    #         args_graph = parse_args(model_args)\n",
    "    #         graph_model = load_graph_model(args_graph)\n",
    "    #         if graph_model is None:\n",
    "    #             continue\n",
    "    #         graph_model.eval()\n",
    "    #         with torch.no_grad():\n",
    "    #             graph_model.to(device)\n",
    "    #             for assay_id in assay_ls:\n",
    "    #                 if assay_id not in prediction_dic:\n",
    "    #                     prediction_dic[assay_id] = dict()\n",
    "    #                     prediction_dic[assay_id]['prediction'] = []\n",
    "    #                     prediction_dic[assay_id]['variance'] = []\n",
    "    #                 if mode == 'test':\n",
    "    #                     task_data_fp = data_test_fp.tensorize_test(assay_id, fold_id)\n",
    "    #                     task_data_graph = data_test_graph.smiles_to_graph_test(assay_id, fold_id)\n",
    "    #                 elif mode == 'valid':\n",
    "    #                     task_data_fp = data_valid_fp.tensorize_test(assay_id, fold_id)\n",
    "    #                     task_data_graph = data_valid_graph.smiles_to_graph_test(assay_id, fold_id)\n",
    "    #                 result_ls = [x.detach().cpu().numpy().reshape(-1) for x in graph_model.prediction_seperate(task_data_graph, device)]\n",
    "    #                 variance_ls = [x.detach().cpu().numpy().reshape(-1) for x in graph_model.prediction_seperate_var(task_data_graph, device)]\n",
    "    #                 prediction_dic[assay_id]['prediction'].extend(result_ls)\n",
    "    #                 prediction_dic[assay_id]['variance'].extend(variance_ls)\n",
    "    #                 torch.cuda.empty_cache()\n",
    "    #     with open(f'../Result_for_publication/fsmol/{few_shot_number}/Fold_{fold_id}/{mode}_{model_architecture}_prediction_dic.pkl', 'wb') as f:\n",
    "    #         pickle.dump(prediction_dic, f)\n",
    "    # FP model prediction, first load then predict\n",
    "    model_architecture = 'FPaugmentRGB'\n",
    "    model_args = [\n",
    "    \"--num_encoder\", \"50\",\n",
    "    \"--dataset\", \"fsmol\",\n",
    "    \"--encode_method\", model_architecture,\n",
    "    \"--random_seed\", \"0\",\n",
    "]\n",
    "    args_fp = parse_args(model_args)\n",
    "    fp_model = load_fp_model(args_fp).to(device)\n",
    "    fp_model.eval()\n",
    "    prediction_dic = {}\n",
    "    label_dic = {}\n",
    "    with torch.no_grad():\n",
    "        for assay_id in assay_ls:\n",
    "            if mode == 'test':\n",
    "                task_data_fp = data_test_fp.tensorize_test(assay_id, fold_id)\n",
    "                # task_data_graph = data_test_graph.smiles_to_graph_test(assay_id, fold_id)\n",
    "            elif mode == 'valid':\n",
    "                task_data_fp = data_valid_fp.tensorize_test(assay_id, fold_id)\n",
    "                # task_data_graph = data_valid_graph.smiles_to_graph_test(assay_id, fold_id)\n",
    "            result_ls = [x.detach().cpu().numpy().reshape(-1) for x in fp_model.prediction_seperate(task_data_fp, device)]\n",
    "            variance_ls = [x.detach().cpu().numpy().reshape(-1) for x in fp_model.prediction_seperate_var(task_data_fp, device)]\n",
    "            prediction_dic[assay_id] = dict()\n",
    "            prediction_dic[assay_id]['prediction'] = result_ls\n",
    "            prediction_dic[assay_id]['variance'] = variance_ls\n",
    "            label_dic[assay_id] = task_data_fp[3].numpy()\n",
    "            torch.cuda.empty_cache()\n",
    "    with open(f'../Result_for_publication/fsmol/{few_shot_number}/Fold_{fold_id}/{mode}_{model_architecture}_prediction_dic.pkl', 'wb') as f:\n",
    "        pickle.dump(prediction_dic, f)\n",
    "    with open(f'../Result_for_publication/fsmol/{few_shot_number}/Fold_{fold_id}/{mode}_label_dic.pkl', 'wb') as f:\n",
    "        pickle.dump(label_dic, f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3733766/294271057.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "print(few_shot_number)\n",
    "for fold_id in range(10):\n",
    "    # get_prediction_dict_per_model(test_assay_ls, device, fold_id, 'test')\n",
    "    get_prediction_dict_per_model(eval_assay_ls, device, fold_id, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3733766/294271057.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n",
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FPaugmentRGB_Num:50_NCL:False_seed:0.pth\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "for fold_id in range(10):\n",
    "    get_prediction_dict_per_model(test_assay_ls, device, fold_id, 'test')\n",
    "    # get_prediction_dict_per_model(eval_assay_ls, device, fold_id, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3548391092873875\n"
     ]
    }
   ],
   "source": [
    "r2_fold_ls = []\n",
    "mse_fold_ls = []\n",
    "# mode = 'valid'\n",
    "mode = 'test'\n",
    "model_ls = ['FP', 'GraphGAT', 'GraphGIN', 'GraphSAGE']\n",
    "for fold_id in range(10):\n",
    "    with open(f'../Result_for_publication/fsmol/32/Fold_{fold_id}/{mode}_label_dic.pkl', 'rb') as f:\n",
    "        label_dic = pickle.load(f)\n",
    "    model_dic = dict()\n",
    "    for model in model_ls:\n",
    "        with open(f'../Result_for_publication/fsmol/32/Fold_{fold_id}/{mode}_{model}_prediction_dic.pkl', 'rb') as f:\n",
    "            prediction_dic_temp = pickle.load(f)\n",
    "        model_dic[model] = prediction_dic_temp\n",
    "    r2_all = []\n",
    "    ls_top25 = []\n",
    "    ls_top50 = []\n",
    "    ls_top75 = []\n",
    "    ls_top100 = []\n",
    "    for assay_id in label_dic:\n",
    "        label = label_dic[assay_id]\n",
    "        prediction_per_model_dic = {}\n",
    "        for model in model_ls:\n",
    "            prediction_per_model_dic[model] = {}\n",
    "            model_prediction_temp = 0\n",
    "            model_pred_uncertainty = 0\n",
    "            for i in range(len(model_dic[model][assay_id]['prediction'])):\n",
    "                model_prediction_temp += model_dic[model][assay_id]['prediction'][i]\n",
    "                model_pred_uncertainty += model_dic[model][assay_id]['variance'][i]\n",
    "            model_prediction_temp /= len(model_dic[model][assay_id]['prediction'])\n",
    "            model_pred_uncertainty /= len(model_dic[model][assay_id]['variance'])\n",
    "            prediction_per_model_dic[model]['prediction'] = model_prediction_temp\n",
    "            prediction_per_model_dic[model]['variance'] = model_pred_uncertainty\n",
    "\n",
    "        prediction_all = 0\n",
    "        uncertainty_all = 0\n",
    "        for model in model_ls:\n",
    "            prediction_all += prediction_per_model_dic[model]['prediction']\n",
    "            uncertainty_all += prediction_per_model_dic[model]['variance']\n",
    "        # prediction_all = (FP_prediction + GAT_prediction + GIN_prediction)/4\n",
    "        # prediction_all = FP_prediction * 0.32 + GAT_prediction * 0.243 + GIN_prediction * 0.289 + SAGE_prediction * 0.147\n",
    "        # uncertainty_all = (FP_uncertainty + GAT_uncertainty + GIN_uncertainty + SAGE_uncertainty)/4\n",
    "        \n",
    "        # Using MSE\n",
    "#         pred_var_nest = [(x,y,z) for x,y,z in zip(prediction_all.tolist(),uncertainty_all.tolist(),label.tolist())]\n",
    "#         pred_var_nest = sorted(pred_var_nest, key = lambda x: x[1])\n",
    "#         pred_var_nest_top25 = pred_var_nest[:int(len(pred_var_nest)*0.25)]\n",
    "#         pred_var_nest_top50 = pred_var_nest[:int(len(pred_var_nest)*0.5)]\n",
    "#         pred_var_nest_top75 = pred_var_nest[:int(len(pred_var_nest)*0.75)]\n",
    "#         pred_var_nest_top100 = pred_var_nest[:int(len(pred_var_nest)*1)]\n",
    "#         top25_mse = np.mean([(x[0]-x[2])**2 for x in pred_var_nest_top25])\n",
    "#         top50_mse = np.mean([(x[0]-x[2])**2 for x in pred_var_nest_top50])\n",
    "#         top76_mse = np.mean([(x[0]-x[2])**2 for x in pred_var_nest_top75])\n",
    "#         top100_mse = np.mean([(x[0]-x[2])**2 for x in pred_var_nest_top100])\n",
    "#         ls_top25.append(top25_mse)\n",
    "#         ls_top50.append(top50_mse)\n",
    "#         ls_top75.append(top76_mse)\n",
    "#         ls_top100.append(top100_mse)\n",
    "#     mse_fold_ls.append([np.mean(ls_top25), np.mean(ls_top50), np.mean(ls_top75), np.mean(ls_top100)])\n",
    "# print(np.array(mse_fold_ls).mean(axis = 0))\n",
    "\n",
    "# Uing R2\n",
    "        r2 = np.corrcoef(label, prediction_all)[0,1]\n",
    "        if r2 < 0:\n",
    "            r2 = 0\n",
    "        else:\n",
    "            r2 = r2**2\n",
    "        r2_all.append(r2)\n",
    "    r2_fold_ls.append(np.mean(r2_all))\n",
    "print(np.mean(r2_fold_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.35710921798343065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.811534881591797, 0.009056243114173412, 3.8238472938537598),\n",
       " (5.502735137939453, 0.009488408453762531, 5.617861270904541),\n",
       " (3.9729208946228027, 0.37018463015556335, 4.196750640869141),\n",
       " (5.396819114685059, 0.40520480275154114, 4.841822147369385),\n",
       " (5.832515716552734, 0.41142168641090393, 5.447168350219727),\n",
       " (5.081961631774902, 0.42114385962486267, 4.603769302368164),\n",
       " (5.333837985992432, 0.43645018339157104, 5.5947113037109375),\n",
       " (5.333860874176025, 0.4364800453186035, 5.424950122833252),\n",
       " (4.391822814941406, 0.448026180267334, 4.980863094329834),\n",
       " (4.4723076820373535, 0.4488449990749359, 4.480627059936523),\n",
       " (5.265296459197998, 0.4604617953300476, 4.844187259674072),\n",
       " (5.9432268142700195, 0.4768209755420685, 5.883322238922119),\n",
       " (4.997929096221924, 0.48402106761932373, 4.986342430114746),\n",
       " (4.904629707336426, 0.4926944673061371, 4.691989898681641),\n",
       " (4.795138835906982, 0.49879777431488037, 4.043051242828369),\n",
       " (5.091682434082031, 0.5076512694358826, 4.442651271820068),\n",
       " (4.517253875732422, 0.509172797203064, 4.653960227966309),\n",
       " (5.035918235778809, 0.5279701352119446, 5.389071941375732),\n",
       " (4.761337757110596, 0.5389485359191895, 4.744932174682617),\n",
       " (5.030128479003906, 0.5480936169624329, 4.976733684539795),\n",
       " (5.915124893188477, 0.5563006401062012, 6.3135480880737305),\n",
       " (5.409757137298584, 0.5579560399055481, 7.509335041046143),\n",
       " (5.25528621673584, 0.5608459115028381, 6.165417671203613),\n",
       " (4.37525749206543, 0.57109534740448, 5.176149845123291),\n",
       " (5.043694496154785, 0.575795590877533, 5.430222511291504),\n",
       " (4.916019439697266, 0.5786095857620239, 5.379897117614746),\n",
       " (4.4797797203063965, 0.5801864862442017, 4.683981418609619),\n",
       " (4.479780197143555, 0.5802040100097656, 4.682131290435791),\n",
       " (5.425132751464844, 0.5843855142593384, 5.131081581115723),\n",
       " (5.111268997192383, 0.587496280670166, 5.271460056304932),\n",
       " (5.111302375793457, 0.587504506111145, 5.24965238571167),\n",
       " (5.321819305419922, 0.5886836051940918, 5.2364420890808105),\n",
       " (5.193759441375732, 0.5888445377349854, 5.183467388153076),\n",
       " (5.132476329803467, 0.5959051251411438, 4.770684719085693),\n",
       " (4.738765716552734, 0.600554883480072, 4.810556888580322),\n",
       " (4.529305934906006, 0.6027241349220276, 4.311336040496826),\n",
       " (5.231357097625732, 0.6059613823890686, 7.171265125274658),\n",
       " (5.710570812225342, 0.6082922220230103, 6.194405555725098),\n",
       " (5.043968677520752, 0.6159626245498657, 5.9506425857543945),\n",
       " (4.760931015014648, 0.6234684586524963, 4.043051242828369),\n",
       " (5.210330963134766, 0.6275674104690552, 5.288267135620117),\n",
       " (5.745751857757568, 0.6296268105506897, 5.7430033683776855),\n",
       " (4.893266677856445, 0.6299437880516052, 4.770684719085693),\n",
       " (4.667167663574219, 0.6316014528274536, 5.0801615715026855),\n",
       " (4.822357177734375, 0.6348481178283691, 6.398544788360596),\n",
       " (4.381819725036621, 0.635913610458374, 4.143134593963623),\n",
       " (4.738565444946289, 0.6401614546775818, 3.927699565887451),\n",
       " (4.511112689971924, 0.6405479907989502, 5.096813201904297),\n",
       " (4.824372291564941, 0.6407050490379333, 3.968214273452759),\n",
       " (5.0445756912231445, 0.6441841125488281, 4.844187259674072),\n",
       " (4.76356315612793, 0.6442722082138062, 5.922114372253418),\n",
       " (5.358316421508789, 0.6446189880371094, 4.275832653045654),\n",
       " (5.266190528869629, 0.6455966830253601, 5.017279624938965),\n",
       " (5.149535655975342, 0.6468702554702759, 5.6387104988098145),\n",
       " (4.999372482299805, 0.6488409638404846, 5.056245803833008),\n",
       " (5.514610767364502, 0.6494045257568359, 5.849324703216553),\n",
       " (5.624001502990723, 0.6514795422554016, 5.323009967803955),\n",
       " (5.1051859855651855, 0.6526005268096924, 5.293304920196533),\n",
       " (4.979891300201416, 0.6526183485984802, 4.968562602996826),\n",
       " (4.686297416687012, 0.6553875803947449, 4.1401143074035645),\n",
       " (4.908483505249023, 0.6562067866325378, 4.753590106964111),\n",
       " (4.472092628479004, 0.6623626947402954, 3.891820192337036),\n",
       " (4.769473552703857, 0.6670690774917603, 4.248209476470947),\n",
       " (4.953974723815918, 0.6701832413673401, 4.861361503601074),\n",
       " (4.953936576843262, 0.6701835989952087, 5.176149845123291),\n",
       " (4.953965663909912, 0.6702044010162354, 5.173320770263672),\n",
       " (4.785975933074951, 0.6709520220756531, 4.691348075866699),\n",
       " (4.603124141693115, 0.6744132041931152, 3.9602415561676025),\n",
       " (4.90868616104126, 0.6827290654182434, 4.174387454986572),\n",
       " (4.986820697784424, 0.689302921295166, 5.905580043792725),\n",
       " (4.54694128036499, 0.6895909309387207, 4.152456283569336),\n",
       " (5.125837326049805, 0.6910761594772339, 5.2278947830200195),\n",
       " (4.469304084777832, 0.6917397975921631, 4.060442924499512),\n",
       " (4.469310760498047, 0.6917547583580017, 4.183575630187988),\n",
       " (4.357633113861084, 0.692489504814148, 4.730921268463135),\n",
       " (6.041075706481934, 0.6928843259811401, 6.175867080688477),\n",
       " (4.785462379455566, 0.7010384798049927, 5.505331516265869),\n",
       " (5.457568168640137, 0.7022364735603333, 5.720311641693115),\n",
       " (5.14046049118042, 0.7037732601165771, 6.373115062713623),\n",
       " (5.44650411605835, 0.7039965987205505, 5.7268476486206055),\n",
       " (5.000702857971191, 0.7040882110595703, 4.49747371673584),\n",
       " (4.995416164398193, 0.7051327228546143, 5.157905101776123),\n",
       " (5.014414310455322, 0.7160442471504211, 4.841506481170654),\n",
       " (4.461784839630127, 0.7188737392425537, 4.928701877593994),\n",
       " (4.837673664093018, 0.7227733135223389, 5.63478946685791),\n",
       " (4.8237199783325195, 0.7241389751434326, 5.619676113128662),\n",
       " (5.029262542724609, 0.7242437601089478, 5.2907891273498535),\n",
       " (5.420228958129883, 0.7249320149421692, 4.983606815338135),\n",
       " (4.707276344299316, 0.7264874577522278, 6.212605953216553),\n",
       " (4.676291465759277, 0.7279089689254761, 4.530446529388428),\n",
       " (4.774112701416016, 0.7284267544746399, 5.713732719421387),\n",
       " (4.957152366638184, 0.7286062240600586, 4.999911308288574),\n",
       " (4.836064338684082, 0.7290500402450562, 3.8188107013702393),\n",
       " (5.779366970062256, 0.7306584119796753, 7.145984649658203),\n",
       " (4.355253219604492, 0.7325155138969421, 4.774068832397461),\n",
       " (5.4573564529418945, 0.7350482940673828, 5.746203422546387),\n",
       " (5.160264015197754, 0.7364832758903503, 5.684939384460449),\n",
       " (5.250787734985352, 0.7370748519897461, 5.801544189453125),\n",
       " (4.736184120178223, 0.7396243214607239, 4.430816650390625),\n",
       " (5.365729808807373, 0.7424046397209167, 5.6200385093688965),\n",
       " (5.052403450012207, 0.7473215460777283, 8.023551940917969),\n",
       " (4.729479789733887, 0.7484238147735596, 4.312140464782715),\n",
       " (4.458719730377197, 0.7497050762176514, 4.174387454986572),\n",
       " (4.9352312088012695, 0.7523651123046875, 6.029001235961914),\n",
       " (4.888733863830566, 0.75343918800354, 5.808743000030518),\n",
       " (4.815346717834473, 0.7562679052352905, 5.218732833862305),\n",
       " (4.99315881729126, 0.759623646736145, 5.945420742034912),\n",
       " (5.11564826965332, 0.7656327486038208, 5.429345607757568),\n",
       " (4.860725402832031, 0.7670205235481262, 3.9512436389923096),\n",
       " (4.7267069816589355, 0.7719488143920898, 4.157162666320801),\n",
       " (4.755280494689941, 0.7744126319885254, 6.004380702972412),\n",
       " (4.75529146194458, 0.7744396924972534, 6.003887176513672),\n",
       " (4.935304164886475, 0.7762495279312134, 5.076423168182373),\n",
       " (4.661647319793701, 0.7812485694885254, 3.8501474857330322),\n",
       " (4.995125770568848, 0.7855254411697388, 4.748404502868652),\n",
       " (5.591946601867676, 0.7872518301010132, 5.0330491065979),\n",
       " (4.799245357513428, 0.7882622480392456, 4.574710845947266),\n",
       " (5.209448337554932, 0.7922470569610596, 4.955827236175537),\n",
       " (4.9352312088012695, 0.7951394319534302, 5.119967937469482),\n",
       " (4.920999526977539, 0.7955710291862488, 4.7004804611206055),\n",
       " (4.997797012329102, 0.7974148988723755, 3.8501474857330322),\n",
       " (5.161030292510986, 0.7978591918945312, 5.5947113037109375),\n",
       " (4.911880016326904, 0.7978905439376831, 5.1556010246276855),\n",
       " (5.241034507751465, 0.7983134984970093, 4.573266506195068),\n",
       " (4.890054225921631, 0.7995617389678955, 5.664348602294922),\n",
       " (5.54142427444458, 0.8042336702346802, 6.210599899291992),\n",
       " (5.560246467590332, 0.8076772689819336, 4.8121843338012695),\n",
       " (4.9707136154174805, 0.8126809597015381, 4.885827541351318),\n",
       " (4.990662097930908, 0.8137456178665161, 4.398269176483154),\n",
       " (4.863449573516846, 0.8173407316207886, 5.477843284606934),\n",
       " (5.311644554138184, 0.8196404576301575, 5.855931282043457),\n",
       " (5.028197288513184, 0.8199194669723511, 5.810242176055908),\n",
       " (4.98042106628418, 0.8205341100692749, 5.902633190155029),\n",
       " (4.7520036697387695, 0.821993350982666, 5.351858139038086),\n",
       " (4.544991493225098, 0.8307983875274658, 4.007333278656006),\n",
       " (4.585390567779541, 0.8319363594055176, 4.290459632873535),\n",
       " (4.981912136077881, 0.837956964969635, 5.3927178382873535),\n",
       " (5.132164001464844, 0.8403960466384888, 6.20979642868042),\n",
       " (4.93873405456543, 0.8406035900115967, 4.9904327392578125),\n",
       " (4.767782688140869, 0.8415732979774475, 4.795790672302246),\n",
       " (4.8107147216796875, 0.8479526042938232, 4.356709003448486),\n",
       " (4.778141975402832, 0.848068356513977, 4.454347133636475),\n",
       " (4.612180233001709, 0.8484938740730286, 2.9058074951171875),\n",
       " (4.567228317260742, 0.8553430438041687, 4.276666164398193),\n",
       " (4.928510665893555, 0.8573770523071289, 5.780743598937988),\n",
       " (4.4516825675964355, 0.8580095171928406, 3.610917806625366),\n",
       " (4.816212177276611, 0.8680242300033569, 5.630853176116943),\n",
       " (4.9510722160339355, 0.8687947988510132, 4.204692840576172),\n",
       " (4.494770526885986, 0.8689059615135193, 5.004617214202881),\n",
       " (4.969913959503174, 0.8696176409721375, 6.023447513580322),\n",
       " (4.611565589904785, 0.869731068611145, 4.5555596351623535),\n",
       " (4.8720598220825195, 0.8717062473297119, 5.9964518547058105),\n",
       " (5.216335296630859, 0.8741328120231628, 5.924255847930908),\n",
       " (5.2612433433532715, 0.8752299547195435, 5.297317028045654),\n",
       " (5.069892883300781, 0.8752855658531189, 5.062594890594482),\n",
       " (4.664066314697266, 0.8777461051940918, 5.001123428344727),\n",
       " (4.664041042327881, 0.877802312374115, 5.006627082824707),\n",
       " (4.856505393981934, 0.8785607814788818, 5.214935779571533),\n",
       " (4.296104431152344, 0.8788645267486572, 4.343805313110352),\n",
       " (5.542960166931152, 0.8801758885383606, 5.327876091003418),\n",
       " (4.911657333374023, 0.8828122615814209, 4.219507694244385),\n",
       " (4.864863395690918, 0.8828976154327393, 5.356586456298828),\n",
       " (4.652003288269043, 0.8909518718719482, 4.5697503089904785),\n",
       " (4.932655334472656, 0.8937627673149109, 3.2511494159698486),\n",
       " (5.047598838806152, 0.8948322534561157, 5.242276191711426),\n",
       " (4.7454729080200195, 0.8978373408317566, 4.6151204109191895),\n",
       " (4.8972907066345215, 0.8980057239532471, 6.3818159103393555),\n",
       " (4.873417854309082, 0.9001291990280151, 5.267858028411865),\n",
       " (4.981872081756592, 0.903813898563385, 5.167068958282471),\n",
       " (4.742541313171387, 0.9067689180374146, 5.865617752075195),\n",
       " (4.457308292388916, 0.9174679517745972, 4.204692840576172),\n",
       " (4.817281246185303, 0.9179315567016602, 4.077537536621094),\n",
       " (5.167167663574219, 0.9250609278678894, 5.8788557052612305),\n",
       " (4.964842319488525, 0.9262389540672302, 5.876334190368652),\n",
       " (4.73846960067749, 0.9265793561935425, 3.4210000038146973),\n",
       " (4.818268299102783, 0.9305593371391296, 5.525453090667725),\n",
       " (5.136253833770752, 0.9325321316719055, 5.305789470672607),\n",
       " (4.938594818115234, 0.9335254430770874, 4.793308258056641),\n",
       " (4.3541107177734375, 0.9338231682777405, 4.18965482711792),\n",
       " (4.705060958862305, 0.9380771517753601, 4.060442924499512),\n",
       " (5.285767078399658, 0.9393078088760376, 5.730099678039551),\n",
       " (4.612122058868408, 0.9499499797821045, 4.143134593963623),\n",
       " (4.780074119567871, 0.959956705570221, 4.507777690887451),\n",
       " (4.77081298828125, 0.9607734084129333, 4.802462577819824),\n",
       " (5.9201202392578125, 0.9625040292739868, 6.520621299743652),\n",
       " (4.830204010009766, 0.9758104085922241, 4.7423200607299805),\n",
       " (4.935425758361816, 0.982239842414856, 6.829469203948975),\n",
       " (4.871912956237793, 0.9844570159912109, 4.701025485992432),\n",
       " (4.79866361618042, 0.9875913858413696, 6.2418341636657715),\n",
       " (4.348705291748047, 0.9902547597885132, 5.794232368469238),\n",
       " (4.642919540405273, 0.9907316565513611, 6.129050254821777),\n",
       " (4.772914886474609, 0.9910471439361572, 3.606041193008423),\n",
       " (4.8888092041015625, 0.9912012815475464, 5.641871452331543),\n",
       " (4.381895065307617, 0.9915212392807007, 3.178053855895996),\n",
       " (4.620997428894043, 0.9952325820922852, 6.39547872543335),\n",
       " (4.658753871917725, 0.9963440895080566, 4.141386985778809),\n",
       " (4.974188804626465, 0.9963960647583008, 4.217299461364746),\n",
       " (5.044412612915039, 0.9974355101585388, 6.097849369049072),\n",
       " (4.648761749267578, 0.9983055591583252, 4.332311153411865),\n",
       " (4.544122695922852, 0.9989713430404663, 5.873806476593018),\n",
       " (4.577476501464844, 1.0014015436172485, 3.5835189819335938),\n",
       " (4.467350006103516, 1.0017993450164795, 4.032469272613525),\n",
       " (4.985230445861816, 1.0031070709228516, 6.47219181060791),\n",
       " (5.023847579956055, 1.0045733451843262, 6.048080921173096),\n",
       " (5.322872161865234, 1.0096752643585205, 4.521788597106934),\n",
       " (4.5439133644104, 1.0098896026611328, 3.6755409240722656),\n",
       " (4.869021892547607, 1.0200425386428833, 5.837439060211182),\n",
       " (4.740804195404053, 1.0218744277954102, 5.09925651550293),\n",
       " (4.710616111755371, 1.0268925428390503, 5.471598148345947),\n",
       " (4.767417907714844, 1.034237265586853, 5.276071548461914),\n",
       " (4.98832893371582, 1.0380091667175293, 6.7596845626831055),\n",
       " (4.646266937255859, 1.038270115852356, 3.8751516342163086),\n",
       " (4.1121931076049805, 1.042258858680725, 3.610917806625366),\n",
       " (4.677450180053711, 1.047195315361023, 6.293419361114502),\n",
       " (4.756015300750732, 1.0494399070739746, 4.26997709274292),\n",
       " (4.736276149749756, 1.0594393014907837, 4.806477069854736),\n",
       " (4.802720546722412, 1.0666749477386475, 5.104125499725342),\n",
       " (4.892767906188965, 1.0667301416397095, 3.407841920852661),\n",
       " (4.823486804962158, 1.0737448930740356, 5.359882831573486),\n",
       " (4.867804050445557, 1.0766767263412476, 5.0955891609191895),\n",
       " (4.966872692108154, 1.0783355236053467, 5.084505081176758),\n",
       " (4.766870498657227, 1.0918045043945312, 4.6634392738342285),\n",
       " (4.732892990112305, 1.1057974100112915, 4.6863813400268555),\n",
       " (4.850945472717285, 1.1138144731521606, 4.78832483291626),\n",
       " (4.696006774902344, 1.1145994663238525, 4.911919116973877),\n",
       " (4.891166687011719, 1.1150487661361694, 5.8212690353393555),\n",
       " (4.491652488708496, 1.1180036067962646, 4.595119953155518),\n",
       " (4.682090759277344, 1.1209107637405396, 3.889572858810425),\n",
       " (4.531065940856934, 1.1212997436523438, 5.730099678039551),\n",
       " (4.970630168914795, 1.143968939781189, 5.3003153800964355),\n",
       " (4.729056358337402, 1.145437240600586, 4.78832483291626),\n",
       " (4.517317295074463, 1.1552709341049194, 4.077537536621094),\n",
       " (4.3094072341918945, 1.1577560901641846, 4.276666164398193),\n",
       " (5.083491802215576, 1.1597416400909424, 6.289715766906738),\n",
       " (4.718677520751953, 1.1616661548614502, 4.919981002807617),\n",
       " (4.5063886642456055, 1.161864995956421, 3.4011974334716797),\n",
       " (4.991496562957764, 1.1688493490219116, 6.157614231109619),\n",
       " (4.738005638122559, 1.1727710962295532, 6.273065567016602),\n",
       " (4.917325973510742, 1.1731754541397095, 6.291383743286133),\n",
       " (4.1360554695129395, 1.1910734176635742, 4.110873699188232),\n",
       " (4.645485877990723, 1.2128229141235352, 5.463831901550293),\n",
       " (4.723484992980957, 1.2145135402679443, 5.788736343383789),\n",
       " (4.950592994689941, 1.2497570514678955, 6.143970966339111),\n",
       " (4.320809841156006, 1.252193570137024, 3.761200189590454),\n",
       " (4.36483907699585, 1.261265754699707, 4.356709003448486),\n",
       " (4.698782444000244, 1.294428825378418, 4.70329475402832),\n",
       " (5.102536201477051, 1.3031281232833862, 6.365095138549805),\n",
       " (4.53431510925293, 1.3263611793518066, 3.9120230674743652),\n",
       " (4.567291736602783, 1.3371353149414062, 3.8066625595092773),\n",
       " (4.788873195648193, 1.343858242034912, 5.09375),\n",
       " (4.696643829345703, 1.3743927478790283, 5.168208599090576),\n",
       " (4.7470703125, 1.4096626043319702, 4.219507694244385),\n",
       " (4.23358154296875, 1.4556065797805786, 3.25809645652771),\n",
       " (5.146265983581543, 1.8005131483078003, 5.325932502746582),\n",
       " (4.9968976974487305, 1.8043100833892822, 4.702296733856201),\n",
       " (4.750222206115723, 1.9864625930786133, 6.042395114898682)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_var_nest = [(x,y,z) for x,y,z in zip(prediction_all.tolist(),uncertainty_all.tolist(),label.tolist())]\n",
    "pred_var_nest = sorted(pred_var_nest, key = lambda x: x[1])\n",
    "pred_var_nest_top25 = pred_var_nest[:int(len(pred_var_nest)*0.25)]\n",
    "pred_var_nest_top50 = pred_var_nest[:int(len(pred_var_nest)*0.5)]\n",
    "pred_var_nest_top75 = pred_var_nest[:int(len(pred_var_nest)*0.75)]\n",
    "pred_var_nest_top100 = pred_var_nest[:int(len(pred_var_nest)*1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3738116340544879"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapley_value_func(['FP', 'GraphGAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapley_value_func(model_ls):\n",
    "    if len(model_ls) == 0:\n",
    "        return 0\n",
    "    return_ls = []\n",
    "    for fold_id in range(10):\n",
    "        r2_ls = []\n",
    "        included_model_result = dict()\n",
    "        with open(f'../Result_for_publication/fsmol/32/Fold_{fold_id}/valid_label_dic.pkl', 'rb') as f:\n",
    "            label_dic = pickle.load(f)\n",
    "        for model in model_ls:\n",
    "            ## load model prediction dic\n",
    "            with open(f'../Result_for_publication/fsmol/32/Fold_{fold_id}/valid_{model}_prediction_dic.pkl', 'rb') as f:\n",
    "                prediction_dic = pickle.load(f)\n",
    "            included_model_result[model] = prediction_dic\n",
    "        for assay_id in label_dic:\n",
    "            label = label_dic[assay_id]\n",
    "            prediction = 0\n",
    "            total_model = 0\n",
    "            for model in included_model_result:\n",
    "                for i in range(len(included_model_result[model][assay_id]['prediction'])):\n",
    "                    prediction += included_model_result[model][assay_id]['prediction'][i]\n",
    "                    total_model += 1\n",
    "            prediction /= total_model\n",
    "            r2_ls.append(np.corrcoef(label, prediction)[0,1]**2)\n",
    "        return_ls.append(np.mean(r2_ls))\n",
    "    return np.mean(return_ls)\n",
    "\n",
    "def calculate_shapley(target_index, index_list, value_function):\n",
    "    \"\"\"\n",
    "    Calculate Shapley value for a target index given a list of indices\n",
    "    \n",
    "    Args:\n",
    "        target_index: The index to calculate Shapley value for\n",
    "        index_list: List of all indices\n",
    "        value_function: Function that takes a list of indices and returns a value\n",
    "    \n",
    "    Returns:\n",
    "        Shapley value for the target index\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    n = len(index_list)\n",
    "    shapley_value = 0\n",
    "    \n",
    "    # Remove target_index from index_list\n",
    "    other_indices = [idx for idx in index_list if idx != target_index]\n",
    "    \n",
    "    # Consider all possible coalition sizes\n",
    "    for size in range(len(other_indices) + 1):\n",
    "        # Get all possible coalitions of current size\n",
    "        for coalition in itertools.combinations(other_indices, size):\n",
    "            coalition = list(coalition)\n",
    "            # Calculate marginal contribution\n",
    "            val_with = value_function(coalition + [target_index])\n",
    "            val_without = value_function(coalition)\n",
    "            marginal = val_with - val_without\n",
    "            \n",
    "            # Calculate weight for this coalition size\n",
    "            weight = (size * math.factorial(size) * math.factorial(n - size - 1)) / math.factorial(n)\n",
    "            shapley_value += marginal * weight\n",
    "            \n",
    "    return shapley_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapley value for FP:0.023576453253418412\n",
      "Shapley value for GraphGAT:0.015498431533231037\n",
      "Shapley value for GraphGIN:0.014006743715160645\n",
      "Shapley value for GraphSAGE:0.0010135255521984388\n",
      "Shapley value for GraphGCN:-0.0025286036576556317\n"
     ]
    }
   ],
   "source": [
    "def normalize_list(lst):\n",
    "    total = sum(lst)\n",
    "    return [x/total for x in lst]\n",
    "included_model = ['FP', 'GraphGAT', 'GraphGIN', 'GraphSAGE', 'GraphGCN']\n",
    "shapley_ls = []\n",
    "for target_model in included_model:\n",
    "    sharpley_value = calculate_shapley(target_model, included_model, shapley_value_func)\n",
    "    print(f\"Shapley value for {target_model}:{sharpley_value}\")\n",
    "    shapley_ls.append(sharpley_value)\n",
    "sharpley_dic = {}\n",
    "for target_model, value in zip(included_model, normalize_list(shapley_ls)):\n",
    "    sharpley_dic[target_model] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FP': 0.4572043906796968,\n",
       " 'GraphGAT': 0.300552032550294,\n",
       " 'GraphGIN': 0.2716246017525206,\n",
       " 'GraphSAGE': 0.019654709194395156,\n",
       " 'GraphGCN': -0.04903573417690685}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharpley_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_all = []\n",
    "for file in os.listdir('../Result_for_publication/fsmol/Fold_0/'):\n",
    "    r2_temp = []\n",
    "    with open(os.path.join('../Result_for_publication/fsmol/Fold_0/',file), 'rb') as f:\n",
    "        prediction_dic = pickle.load(f)\n",
    "        assay_id = f.name.split('/')[-1].split('_')[0]\n",
    "        predictions = 0\n",
    "        for model_architecture in ['GraphGAT', 'GraphGIN', 'FP']:\n",
    "            for pred in prediction_dic[model_architecture]:\n",
    "                predictions = predictions + pred\n",
    "                r2 = np.corrcoef(predictions, prediction_dic['label'])[0,1]**2\n",
    "                r2_temp.append(r2)\n",
    "        r2_all.append(r2_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25838974, 0.29894342, 0.31340184, 0.31980244, 0.32545283,\n",
       "       0.3282525 , 0.33042053, 0.33409571, 0.33588793, 0.33687439,\n",
       "       0.33819697, 0.33895774, 0.34032419, 0.34088705, 0.3413782 ,\n",
       "       0.34124164, 0.34245321, 0.34350225, 0.3452554 , 0.34675946,\n",
       "       0.34772487, 0.34813144, 0.34857796, 0.34892422, 0.34994362,\n",
       "       0.35051447, 0.35129061, 0.35090529, 0.35251217, 0.35390182,\n",
       "       0.35479962, 0.35610036, 0.35693849, 0.35710935, 0.35783636,\n",
       "       0.3580899 , 0.35823326, 0.35843064, 0.35866691, 0.35896033,\n",
       "       0.35915937, 0.35896324, 0.35893691, 0.35884749, 0.35884539,\n",
       "       0.35884093, 0.3586924 , 0.35870201, 0.35873038, 0.35854405,\n",
       "       0.35835271, 0.35826526, 0.35838539, 0.35806821, 0.35794055,\n",
       "       0.3577109 , 0.35742788, 0.35707773, 0.35702748, 0.35703141,\n",
       "       0.35687366, 0.35663597, 0.35640636, 0.3563003 , 0.35613367,\n",
       "       0.35589164, 0.3555196 , 0.3552287 , 0.35518676, 0.35496985,\n",
       "       0.35483528, 0.35468238, 0.35449071, 0.35449466, 0.35432746,\n",
       "       0.35413389, 0.35394212, 0.35359991])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_all_array = np.array(r2_all)\n",
    "r2_all_array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7664db600560>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r2_all_array.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_991847/3854074521.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  r2 = np.corrcoef(torch.tensor(y_label).reshape(-1), prediction.detach().cpu().numpy().reshape(-1))[0,1]**2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3536000867723633, 0.3515763975053103, 0.3683508062817459, 0.3484346178556437, 0.34928082851017367] 0.35424854738504735\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, device, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35090627725752666, 0.34574344406430696, 0.35974062016998226, 0.33428008965083833, 0.34033690686505147] 0.34620146760154114\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34676080861023645, 0.34001529593583874, 0.3581471294555243, 0.3291381092584444, 0.33525244364210216] 0.3418627573804292\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34124305154047907, 0.33429049317908904, 0.3544312429865615, 0.3243167483168465, 0.33257982033558037] 0.33737227127171127\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3408887960003255, 0.3326585830346959, 0.353235820195374, 0.3224689266240401, 0.33105475080677427] 0.336061375332242\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3389598601008053, 0.32994289753704054, 0.3520788522282898, 0.32100578754095677, 0.32993013536173615] 0.33438350655376575\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3368769377897742, 0.32493789592481026, 0.34810858197283356, 0.3167857291405009, 0.3273988213573304] 0.33082159323704985\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls,fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3340978315116516, 0.3188870908666155, 0.34326885732316437, 0.31365926049244675, 0.32361275531649203] 0.3267051591020741\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls,fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32825491942645535, 0.3122822984478497, 0.3355368097203841, 0.308689421236851, 0.319703338742639] 0.32089335751483583\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls,fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3198074552812821, 0.3036073623134336, 0.32826100750579623, 0.2996257923659276, 0.3074256168585508] 0.31174544686499805\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls,fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
