{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from deep_ensemble import deep_ensemble_FP as deep_ensemble_MLP\n",
    "from deep_ensemble import deep_ensemble_Graph as deep_ensemble_Graph\n",
    "import math \n",
    "import argparse\n",
    "import sys\n",
    "from tqdm import tqdm \n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "# import get_fsmol_dataloader as fsmol\n",
    "import seaborn as sns\n",
    "from EDKT_data.Data_FP_fsmol import deep_gp_data as deep_gp_data_fp\n",
    "from EDKT_data.Data_Graph_fsmol import deep_gp_data as deep_gp_data_graph\n",
    "import pickle \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_id_train_test_split = np.load('../Data_for_publication/fsmol/split_dic.pkl', allow_pickle=True)\n",
    "test_assay_ls = assay_id_train_test_split['test_assays']\n",
    "eval_assay_ls = assay_id_train_test_split['valid_assays']\n",
    "\n",
    "few_shot_number = 32\n",
    "\n",
    "# load fp data\n",
    "data_path = '../Data_for_publication/fsmol/all_data_fp.pkl'\n",
    "data_path_test = f'../Data_for_publication/fsmol/all_data_fp_test_10fold_{few_shot_number}.pkl'\n",
    "data_path_valid = f'../Data_for_publication/fsmol/all_data_fp_valid_10fold_{few_shot_number}.pkl'\n",
    "data_test_fp = deep_gp_data_fp(data_path, data_path_test)\n",
    "data_valid_fp = deep_gp_data_fp(data_path, data_path_valid)\n",
    "# load graph data\n",
    "data_path = '../Data_for_publication/fsmol/all_data_graph.pkl'\n",
    "data_path_test = f'../Data_for_publication/fsmol/all_data_graph_test_10fold_{few_shot_number}.pkl'\n",
    "data_path_valid = f'../Data_for_publication/fsmol/all_data_graph_valid_10fold_{few_shot_number}.pkl'\n",
    "data_test_graph = deep_gp_data_graph(data_path, data_path_test)\n",
    "data_valid_graph = deep_gp_data_graph(data_path, data_path_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args_list=None):\n",
    "    parser = argparse.ArgumentParser(description=\"DeepGP Training Script\")\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=42, help=\"random_seed\")\n",
    "    parser.add_argument(\"--dataset\", type=str, help=\"what dataset to use\", default='fsmol')\n",
    "    parser.add_argument(\"--encode_method\", type=str, help=\"what encoder to use\", default='FP')\n",
    "    parser.add_argument(\"--num_encoder\", type=int, default=2, help=\"num_encoder\")\n",
    "    parser.add_argument(\"--allow_NCL\", action=\"store_true\", help=\"whether use NCL\")\n",
    "    \n",
    "    # First parse to get dataset and encode_method\n",
    "    temp_args, _ = parser.parse_known_args(args_list)\n",
    "    \n",
    "    if temp_args.dataset == 'fsmol':\n",
    "        parser.add_argument(\"--FP_input_dim\", type=int, default=2024, help=\"FP input dimension\")\n",
    "        parser.add_argument(\"--Graph_input_dim\", type=int, default=32, help=\"Graph input dimension\")\n",
    "    elif temp_args.dataset == 'pQSAR':\n",
    "        parser.add_argument(\"--FP_input_dim\", type=int, default=1024, help=\"FP input dimension\")\n",
    "        parser.add_argument(\"--Graph_input_dim\", type=int, default=30, help=\"Graph input dimension\")\n",
    "        parser.add_argument(\"--group_id\", type=int, default=0, help=\"group_id\")\n",
    "    \n",
    "    parser.add_argument(\"--world_size\", type=int, default=6, help=\"number of GPUs to use\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=10, help=\"batch size\")\n",
    "    if 'FP' in temp_args.encode_method:\n",
    "        parser.add_argument(\"--lr\", type=float, help=\"learning rate\", default=0.001)\n",
    "    elif 'Graph' in temp_args.encode_method:\n",
    "        parser.add_argument(\"--lr\", type=float, help=\"learning rate\", default=0.0005)\n",
    "    \n",
    "    args = parser.parse_args(args_list)\n",
    "    \n",
    "    # Import required modules based on arguments\n",
    "    if 'FP' in args.encode_method:\n",
    "        from deep_ensemble import deep_ensemble_FP as deep_ensemble\n",
    "        if args.dataset == 'fsmol':\n",
    "            from EDKT_data.Data_FP_fsmol import deep_gp_data\n",
    "            from DKT_dataset import MLP_train_dataset_fsmol as train_dataset \n",
    "            from DKT_dataset import MLP_eval_dataset_fsmol as eval_dataset\n",
    "        elif args.dataset == 'pQSAR':\n",
    "            from EDKT_data.Data_FP_pQSAR import deep_gp_data\n",
    "            from DKT_dataset import MLP_train_dataset_pQSAR as train_dataset\n",
    "            from DKT_dataset import MLP_eval_dataset_pQSAR as eval_dataset\n",
    "    elif 'Graph' in args.encode_method:\n",
    "        from deep_ensemble import deep_ensemble_Graph as deep_ensemble\n",
    "        if args.dataset == 'fsmol':\n",
    "            from EDKT_data.Data_Graph_fsmol import deep_gp_data\n",
    "            from DKT_dataset import Graph_train_dataset_fsmol as train_dataset\n",
    "            from DKT_dataset import Graph_eval_dataset_fsmol as eval_dataset\n",
    "        elif args.dataset == 'pQSAR':\n",
    "            from EDKT_data.Data_Graph_pQSAR import deep_gp_data\n",
    "            from DKT_dataset import Graph_train_dataset_pQSAR as train_dataset\n",
    "            from DKT_dataset import Graph_eval_dataset_pQSAR as eval_dataset\n",
    "    \n",
    "    # Add imported modules to args\n",
    "    args.deep_ensemble = deep_ensemble\n",
    "    args.deep_gp_data = deep_gp_data\n",
    "    args.train_dataset = train_dataset\n",
    "    args.eval_dataset = eval_dataset\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load FP model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(deep_ensemble_MLP)\n",
    "def load_fp_model(model_args):\n",
    "    try:\n",
    "        fp_model = deep_ensemble_MLP.ensemble_deep_gp(model_args)\n",
    "        # Load state dict\n",
    "        model_path = f'../Model_for_publication/Dataset:{model_args.dataset}_Method:{model_args.encode_method}_Num:{model_args.num_encoder}_NCL:{model_args.allow_NCL}_seed:{model_args.random_seed}.pth'\n",
    "        state_dict = torch.load(model_path)\n",
    "        # Process state dict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] if k.startswith('module.') else k\n",
    "            new_state_dict[name] = v\n",
    "        # Load and verify\n",
    "        fp_model.load_state_dict(new_state_dict)\n",
    "        fp_model.eval()\n",
    "        # print(f\"✓ FP Model loaded successfully from {model_path}\")\n",
    "        return fp_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(f\"✗ Failed to load FP model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load graph model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(deep_ensemble_Graph)\n",
    "def load_graph_model(model_args):\n",
    "    try:\n",
    "        graph_model = deep_ensemble_Graph.ensemble_deep_gp(model_args)\n",
    "        \n",
    "        # Load state dict\n",
    "        model_path = f'../Model_for_publication/Dataset:{model_args.dataset}_Method:{model_args.encode_method}_Num:{model_args.num_encoder}_NCL:{model_args.allow_NCL}_seed:{model_args.random_seed}.pth'\n",
    "        state_dict = torch.load(model_path)\n",
    "        \n",
    "        # Process state dict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] if k.startswith('module.') else k\n",
    "            new_state_dict[name] = v\n",
    "            \n",
    "        # Load and verify\n",
    "        graph_model.load_state_dict(new_state_dict)\n",
    "        graph_model.eval()\n",
    "        \n",
    "        # print(f\"✓ Model loaded successfully from {model_path}\")\n",
    "        return graph_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(f\"✗ Failed to load model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance_overall_fp(assay_ls, model, folde_id, mode = 'test'):\n",
    "    r2_ls = []\n",
    "    for assay_id in assay_ls:\n",
    "        if mode == 'test':\n",
    "            task_data = data_test_fp.tensorize_test(assay_id, folde_id)\n",
    "        elif mode == 'valid':\n",
    "             task_data = data_valid_fp.tensorize_test(assay_id, folde_id)\n",
    "        prediction = model.prediction(task_data, 'cpu')\n",
    "        y_label = task_data[3]\n",
    "        r2 = np.corrcoef(torch.tensor(y_label).reshape(-1), prediction.detach().cpu().numpy().reshape(-1))[0,1]**2\n",
    "        r2_ls.append(r2)\n",
    "    return r2_ls\n",
    "\n",
    "def get_model_performance_overall_graph(assay_ls, model, folde_id, mode = 'test'):\n",
    "    r2_ls = []\n",
    "    for assay_id in assay_ls:\n",
    "        if mode == 'test':\n",
    "            task_data = data_test_graph.smiles_to_graph_test(assay_id, folde_id)\n",
    "        elif mode == 'valid':\n",
    "             task_data = data_valid_graph.smiles_to_graph_test(assay_id, folde_id)\n",
    "        prediction = model.prediction(task_data, 'cpu')\n",
    "        y_label = task_data[3]\n",
    "        r2 = np.corrcoef(torch.tensor(y_label).reshape(-1), prediction.detach().cpu().numpy().reshape(-1))[0,1]**2\n",
    "        r2_ls.append(r2)\n",
    "    return r2_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1852812/294271057.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FP Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:FP_Num:50_NCL:False_seed:42.pth\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "model_args = [\n",
    "    \"--num_encoder\", \"50\",\n",
    "    \"--dataset\", \"fsmol\",\n",
    "    \"--encode_method\", \"FP\",\n",
    "]\n",
    "args_fp = parse_args(model_args)\n",
    "fp_model = load_fp_model(args_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded successfully from ../Model_for_publication/Dataset:fsmol_Method:GraphGAT_Num:2_NCL:False_seed:0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1852812/2266367852.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "model_args = [\n",
    "    \"--num_encoder\", \"2\",\n",
    "    \"--dataset\", \"fsmol\",\n",
    "    \"--encode_method\", \"GraphGAT\",\n",
    "    \"--random_seed\", \"0\",\n",
    "]\n",
    "args_graph = parse_args(model_args)\n",
    "graph_model = load_graph_model(args_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2989472942854827\n"
     ]
    }
   ],
   "source": [
    "# r2_ls_fp = get_model_performance_overall_fp(test_assay_ls, fp_model, 0 ,'test')\n",
    "# print(np.mean(r2_ls_fp))\n",
    "# r2_ls_graph = get_model_performance_overall_graph(test_assay_ls, graph_model, 0, 'test')\n",
    "# print(np.mean(r2_ls_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_dict_per_model(assay_ls, device, fold_id, mode = 'test'):\n",
    "    # graph model prediction, first load then predict\n",
    "    for model_architecture in ['GraphGAT', 'GraphGIN', 'GraphSAGE']:\n",
    "        prediction_dic = {}\n",
    "        for random_seed in range(11):\n",
    "            model_args = [\n",
    "                \"--num_encoder\", \"2\",\n",
    "                \"--dataset\", \"fsmol\",\n",
    "                \"--encode_method\", model_architecture,\n",
    "                \"--random_seed\", str(random_seed),\n",
    "            ]\n",
    "            args_graph = parse_args(model_args)\n",
    "            graph_model = load_graph_model(args_graph)\n",
    "            if graph_model is None:\n",
    "                continue\n",
    "            graph_model.eval()\n",
    "            with torch.no_grad():\n",
    "                graph_model.to(device)\n",
    "                for assay_id in assay_ls:\n",
    "                    if assay_id not in prediction_dic:\n",
    "                        prediction_dic[assay_id] = []\n",
    "                    if mode == 'test':\n",
    "                        task_data_fp = data_test_fp.tensorize_test(assay_id, fold_id)\n",
    "                        task_data_graph = data_test_graph.smiles_to_graph_test(assay_id, fold_id)\n",
    "                    elif mode == 'valid':\n",
    "                        task_data_fp = data_valid_fp.tensorize_test(assay_id, fold_id)\n",
    "                        task_data_graph = data_valid_graph.smiles_to_graph_test(assay_id, fold_id)\n",
    "                    result_ls = [x.detach().cpu().numpy().reshape(-1) for x in graph_model.prediction_seperate(task_data_graph, device)]\n",
    "                    prediction_dic[assay_id].extend(result_ls)\n",
    "                    torch.cuda.empty_cache()\n",
    "        with open(f'../Result_for_publication/fsmol/Fold_{fold_id}/{model_architecture}_prediction_dic.pkl', 'wb') as f:\n",
    "            pickle.dump(prediction_dic, f)\n",
    "    # FP model prediction, first load then predict\n",
    "    model_args = [\n",
    "    \"--num_encoder\", \"50\",\n",
    "    \"--dataset\", \"fsmol\",\n",
    "    \"--encode_method\", \"FP\",\n",
    "]\n",
    "    args_fp = parse_args(model_args)\n",
    "    fp_model = load_fp_model(args_fp).to(device)\n",
    "    fp_model.eval()\n",
    "    prediction_dic = {}\n",
    "    label_dic = {}\n",
    "    with torch.no_grad():\n",
    "        for assay_id in assay_ls:\n",
    "            if mode == 'test':\n",
    "                task_data_fp = data_test_fp.tensorize_test(assay_id, fold_id)\n",
    "                task_data_graph = data_test_graph.smiles_to_graph_test(assay_id, fold_id)\n",
    "            elif mode == 'valid':\n",
    "                task_data_fp = data_valid_fp.tensorize_test(assay_id, fold_id)\n",
    "                task_data_graph = data_valid_graph.smiles_to_graph_test(assay_id, fold_id)\n",
    "            result_ls = [x.detach().cpu().numpy().reshape(-1) for x in fp_model.prediction_seperate(task_data_fp, device)]\n",
    "            prediction_dic[assay_id] = result_ls\n",
    "            label_dic[assay_id] = task_data_fp[3].numpy()\n",
    "            torch.cuda.empty_cache()\n",
    "    with open(f'../Result_for_publication/fsmol/Fold_{fold_id}/{'FP'}_prediction_dic.pkl', 'wb') as f:\n",
    "        pickle.dump(prediction_dic, f)\n",
    "    with open(f'../Result_for_publication/fsmol/Fold_{fold_id}/label_dic.pkl', 'wb') as f:\n",
    "        pickle.dump(label_dic, f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2138243/1575216691.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_2138243/1570656503.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "for fold_id in range(5):\n",
    "    get_prediction_dict_per_model(test_assay_ls, device, fold_id, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3579320561908158\n"
     ]
    }
   ],
   "source": [
    "r2_fold_ls = []\n",
    "for fold_id in range(5):\n",
    "    with open(f'../Result_for_publication/fsmol/Fold_{fold_id}/label_dic.pkl', 'rb') as f:\n",
    "        label_dic = pickle.load(f)\n",
    "    with open(f'../Result_for_publication/fsmol/Fold_{fold_id}/FP_prediction_dic.pkl', 'rb') as f:\n",
    "        FP_prediction_dic = pickle.load(f)\n",
    "    with open(f'../Result_for_publication/fsmol/Fold_{fold_id}/GraphGAT_prediction_dic.pkl', 'rb') as f:\n",
    "        GraphGAT_prediction_dic = pickle.load(f)\n",
    "    with open(f'../Result_for_publication/fsmol/Fold_{fold_id}/GraphGIN_prediction_dic.pkl', 'rb') as f:\n",
    "        GraphGIN_prediction_dic = pickle.load(f)\n",
    "    with open(f'../Result_for_publication/fsmol/Fold_{fold_id}/GraphSAGE_prediction_dic.pkl', 'rb') as f:\n",
    "        GraphSAGE_prediction_dic = pickle.load(f)\n",
    "    r2_all = []\n",
    "    for assay_id in label_dic:\n",
    "        label = label_dic[assay_id]\n",
    "        GAT_prediction = 0\n",
    "        for i in range(11):\n",
    "            GAT_prediction += GraphGAT_prediction_dic[assay_id][i]\n",
    "        GAT_prediction /= len(GraphGAT_prediction_dic[assay_id])\n",
    "        GIN_prediction = 0\n",
    "        for i in range(11):\n",
    "            GIN_prediction += GraphGIN_prediction_dic[assay_id][i]\n",
    "        GIN_prediction /= len(GraphGIN_prediction_dic[assay_id])\n",
    "        SAGE_prediction = 0\n",
    "        for i in range(len(GraphSAGE_prediction_dic[assay_id])):\n",
    "            SAGE_prediction += GraphSAGE_prediction_dic[assay_id][i]\n",
    "        SAGE_prediction /= len(GraphSAGE_prediction_dic[assay_id])\n",
    "        FP_prediction = 0\n",
    "        for i in range(50):\n",
    "            FP_prediction += FP_prediction_dic[assay_id][i]\n",
    "        FP_prediction /= len(FP_prediction_dic[assay_id])\n",
    "        prediction_all = GAT_prediction + GIN_prediction + FP_prediction\n",
    "        r2 = np.corrcoef(label, prediction_all)[0,1]**2\n",
    "        r2_all.append(r2)\n",
    "    r2_fold_ls.append(np.mean(r2_all))\n",
    "print(np.mean(r2_fold_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3589377484590077\n"
     ]
    }
   ],
   "source": [
    "r2_all = []\n",
    "for assay_id in label_dic:\n",
    "    label = label_dic[assay_id]\n",
    "    GAT_prediction = 0\n",
    "    for i in range(len(GraphGAT_prediction_dic[assay_id])):\n",
    "        GAT_prediction += GraphGAT_prediction_dic[assay_id][i]\n",
    "    GAT_prediction /= len(GraphGAT_prediction_dic[assay_id])\n",
    "    GIN_prediction = 0\n",
    "    for i in range(len(GraphGIN_prediction_dic[assay_id])):\n",
    "        GIN_prediction += GraphGIN_prediction_dic[assay_id][i]\n",
    "    GIN_prediction /= len(GraphGIN_prediction_dic[assay_id])\n",
    "    SAGE_prediction = 0\n",
    "    for i in range(len(GraphSAGE_prediction_dic[assay_id])):\n",
    "        SAGE_prediction += GraphSAGE_prediction_dic[assay_id][i]\n",
    "    SAGE_prediction /= len(GraphSAGE_prediction_dic[assay_id])\n",
    "    FP_prediction = 0\n",
    "    for i in range(len(FP_prediction_dic[assay_id])):\n",
    "        FP_prediction += FP_prediction_dic[assay_id][i]\n",
    "    FP_prediction /= len(FP_prediction_dic[assay_id])\n",
    "    prediction_all = GAT_prediction + GIN_prediction + FP_prediction\n",
    "    r2 = np.corrcoef(label, prediction_all)[0,1]**2\n",
    "    r2_all.append(r2)\n",
    "print(np.mean(r2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_all = []\n",
    "for file in os.listdir('../Result_for_publication/fsmol/Fold_0/'):\n",
    "    r2_temp = []\n",
    "    with open(os.path.join('../Result_for_publication/fsmol/Fold_0/',file), 'rb') as f:\n",
    "        prediction_dic = pickle.load(f)\n",
    "        assay_id = f.name.split('/')[-1].split('_')[0]\n",
    "        predictions = 0\n",
    "        for model_architecture in ['GraphGAT', 'GraphGIN', 'FP']:\n",
    "            for pred in prediction_dic[model_architecture]:\n",
    "                predictions = predictions + pred\n",
    "                r2 = np.corrcoef(predictions, prediction_dic['label'])[0,1]**2\n",
    "                r2_temp.append(r2)\n",
    "        r2_all.append(r2_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25838974, 0.29894342, 0.31340184, 0.31980244, 0.32545283,\n",
       "       0.3282525 , 0.33042053, 0.33409571, 0.33588793, 0.33687439,\n",
       "       0.33819697, 0.33895774, 0.34032419, 0.34088705, 0.3413782 ,\n",
       "       0.34124164, 0.34245321, 0.34350225, 0.3452554 , 0.34675946,\n",
       "       0.34772487, 0.34813144, 0.34857796, 0.34892422, 0.34994362,\n",
       "       0.35051447, 0.35129061, 0.35090529, 0.35251217, 0.35390182,\n",
       "       0.35479962, 0.35610036, 0.35693849, 0.35710935, 0.35783636,\n",
       "       0.3580899 , 0.35823326, 0.35843064, 0.35866691, 0.35896033,\n",
       "       0.35915937, 0.35896324, 0.35893691, 0.35884749, 0.35884539,\n",
       "       0.35884093, 0.3586924 , 0.35870201, 0.35873038, 0.35854405,\n",
       "       0.35835271, 0.35826526, 0.35838539, 0.35806821, 0.35794055,\n",
       "       0.3577109 , 0.35742788, 0.35707773, 0.35702748, 0.35703141,\n",
       "       0.35687366, 0.35663597, 0.35640636, 0.3563003 , 0.35613367,\n",
       "       0.35589164, 0.3555196 , 0.3552287 , 0.35518676, 0.35496985,\n",
       "       0.35483528, 0.35468238, 0.35449071, 0.35449466, 0.35432746,\n",
       "       0.35413389, 0.35394212, 0.35359991])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_all_array = np.array(r2_all)\n",
    "r2_all_array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7664db600560>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r2_all_array.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_991847/3854074521.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  r2 = np.corrcoef(torch.tensor(y_label).reshape(-1), prediction.detach().cpu().numpy().reshape(-1))[0,1]**2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3536000867723633, 0.3515763975053103, 0.3683508062817459, 0.3484346178556437, 0.34928082851017367] 0.35424854738504735\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, device, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35090627725752666, 0.34574344406430696, 0.35974062016998226, 0.33428008965083833, 0.34033690686505147] 0.34620146760154114\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34676080861023645, 0.34001529593583874, 0.3581471294555243, 0.3291381092584444, 0.33525244364210216] 0.3418627573804292\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34124305154047907, 0.33429049317908904, 0.3544312429865615, 0.3243167483168465, 0.33257982033558037] 0.33737227127171127\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3408887960003255, 0.3326585830346959, 0.353235820195374, 0.3224689266240401, 0.33105475080677427] 0.336061375332242\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3389598601008053, 0.32994289753704054, 0.3520788522282898, 0.32100578754095677, 0.32993013536173615] 0.33438350655376575\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls, fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3368769377897742, 0.32493789592481026, 0.34810858197283356, 0.3167857291405009, 0.3273988213573304] 0.33082159323704985\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls,fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3340978315116516, 0.3188870908666155, 0.34326885732316437, 0.31365926049244675, 0.32361275531649203] 0.3267051591020741\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls,fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32825491942645535, 0.3122822984478497, 0.3355368097203841, 0.308689421236851, 0.319703338742639] 0.32089335751483583\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls,fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3198074552812821, 0.3036073623134336, 0.32826100750579623, 0.2996257923659276, 0.3074256168585508] 0.31174544686499805\n"
     ]
    }
   ],
   "source": [
    "r2_ls_fold = []\n",
    "for fold_id in range(5):\n",
    "    r2_ls_graph = get_model_performance_overall_combine(test_assay_ls, model_ls,fp_model, fold_id, 'test')\n",
    "    r2_ls_fold.append(np.mean(r2_ls_graph))\n",
    "print(r2_ls_fold,np.mean(r2_ls_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
